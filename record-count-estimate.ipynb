{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of reddit posts from a sample\n",
    "\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_file = 'Reddit_Posts/zipped/reddit-post-counts.txt'\n",
    "\n",
    "with open(reddit_file) as f:\n",
    "    contents = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RC_2006-12:61018',\n",
       " 'RC_2007-11:372983',\n",
       " 'RC_2008-10:789874',\n",
       " 'RC_2009-09:2032276',\n",
       " 'RC_2010-08:4247982',\n",
       " 'RC_2011-07:10557466',\n",
       " 'RC_2012-06:21897913',\n",
       " 'RC_2013-05:33126225',\n",
       " 'RC_2014-04:42440735',\n",
       " 'RC_2015-04:55005780']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [line.split(':')[1] for line in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_array = np.array(counts).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_array = count_array[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   61018.,   372983.,   789874.,  2032276.,  4247982., 10557466.,\n",
       "       21897913., 33126225., 42440735.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12836274.666666666\n",
      "5005619.266566533\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(count_array), (np.std(count_array) / np.sqrt(len(count_array))), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(count_array)\n",
    "stderr = (np.std(count_array) / np.sqrt(len(count_array)))\n",
    "alpha = (1.96 * stderr)\n",
    "ci_low = mean - alpha\n",
    "ci_high = mean + alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12836274.666666666\n",
      "5005619.266566533\n",
      "9811013.762470404\n",
      "3025260.9041962624\n",
      "22647288.42913707\n"
     ]
    }
   ],
   "source": [
    "print(mean, stderr, alpha, ci_low, ci_high, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1386317664.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean * (12 * len(count_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16601760.950575175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sqrt(np.var(count_array) * (len(count_array)^2))) / np.sqrt(len(count_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, if I did the math right, then the expected number of records will be 1.39B with a standard error of 16M. With alpha = 1.96 that is approx.\n",
    "# 1.44B records at the high end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit-nlp-env",
   "language": "python",
   "name": "reddit-nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
